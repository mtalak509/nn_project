import streamlit as st
import torch
import torch.nn as nn
import torchvision.models as models
import torchvision.transforms as T
from PIL import Image
import matplotlib.pyplot as plt
import numpy as np
import pandas as pd
import seaborn as sns
import time
import requests
from io import BytesIO
import plotly.graph_objects as go
import plotly.express as px
import os

# –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ —Å—Ç—Ä–∞–Ω–∏—Ü—ã
st.set_page_config(
    page_title="Intel Image Classification",
    page_icon="üåÑ",
    layout="wide"
)

# –∫–ª–∞—Å—Å—ã –º–æ–¥–µ–ª–∏
CLASS_NAMES = ['buildings', 'forest', 'glacier', 'mountain', 'sea', 'street']

# –ø—É—Ç—å –∫ –º–æ–¥–µ–ª–∏
MODEL_PATH = 'models/model_1_params/intel_image_classifier_resnet50.pth'

# –∑–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏
@st.cache_resource
def load_model():
    """–ó–∞–≥—Ä—É–∂–∞–µ—Ç –æ–±—É—á–µ–Ω–Ω—É—é –º–æ–¥–µ–ª—å"""
    try:
        model = models.resnet50(pretrained=False)
        model.fc = nn.Linear(model.fc.in_features, 6)

        # –∑–∞–≥—Ä—É–∂–∞–µ–º –≤–µ—Å–∞ –º–æ–¥–µ–ª–∏ –ø–æ –ø—Ä–∞–≤–∏–ª—å–Ω–æ–º—É –ø—É—Ç–∏
        checkpoint = torch.load(MODEL_PATH, map_location='cpu')
        model.load_state_dict(checkpoint['model_state_dict'])
        model.eval()
        return model, checkpoint
    except Exception as e:
        st.error(f"–û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –º–æ–¥–µ–ª–∏: {e}")
        st.info(f"–ü—Ä–æ–≤–µ—Ä—å—Ç–µ –ø—É—Ç—å: {MODEL_PATH}")
        return None, None

# —Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–∞—Ü–∏–∏
def get_transforms():
    return T.Compose([
        T.Resize((224, 224)),
        T.ToTensor(),
        T.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
    ])

# —Ñ—É–Ω–∫—Ü–∏—è –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è
def predict_image(model, image, transforms):
    """–ü—Ä–µ–¥—Å–∫–∞–∑—ã–≤–∞–µ—Ç –∫–ª–∞—Å—Å –¥–ª—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è —Å –∏–∑–º–µ—Ä–µ–Ω–∏–µ–º –≤—Ä–µ–º–µ–Ω–∏"""
    start_time = time.time()

    image_tensor = transforms(image).unsqueeze(0)
    with torch.no_grad():
        outputs = model(image_tensor)
        probabilities = torch.nn.functional.softmax(outputs[0], dim=0)
        predicted_class = torch.argmax(outputs[0]).item()
        confidence = probabilities[predicted_class].item()

    inference_time = time.time() - start_time
    return predicted_class, confidence, probabilities, inference_time

# –∑–∞–≥—Ä—É–∑–∫–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –ø–æ URL
def load_image_from_url(url):
    try:
        response = requests.get(url, timeout=10)
        image = Image.open(BytesIO(response.content))
        return image
    except Exception as e:
        st.error(f"–û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è: {e}")
        return None

# –≥–ª–∞–≤–Ω–∞—è —Å—Ç—Ä–∞–Ω–∏—Ü–∞
def show_main_page():
    st.title("Intel Image Classification")
    st.markdown("---")

    # –∑–∞–≥—Ä—É–∂–∞–µ–º –º–æ–¥–µ–ª—å –∏ –¥–∞–Ω–Ω—ã–µ
    model, checkpoint = load_model()

    if model is None:
        st.error("–ú–æ–¥–µ–ª—å –Ω–µ –∑–∞–≥—Ä—É–∂–µ–Ω–∞. –£–±–µ–¥–∏—Ç–µ—Å—å, —á—Ç–æ —Ñ–∞–π–ª –º–æ–¥–µ–ª–∏ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç.")
        return

    # –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –ø—Ä–æ—Ü–µ—Å—Å–µ –æ–±—É—á–µ–Ω–∏—è
    st.header("–ü—Ä–æ—Ü–µ—Å—Å –æ–±—É—á–µ–Ω–∏—è –º–æ–¥–µ–ª–∏")

    col1, col2 = st.columns(2)

    with col1:
        st.subheader("üß† –ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞ –º–æ–¥–µ–ª–∏")
        st.info("""
        - **–ë–∞–∑–æ–≤–∞—è –º–æ–¥–µ–ª—å:** ResNet50 (–ø—Ä–µ–¥–æ–±—É—á–µ–Ω–Ω–∞—è –Ω–∞ ImageNet)
        - **Transfer Learning:** –ó–∞–º–æ—Ä–æ–∂–µ–Ω—ã –≤—Å–µ —Å–ª–æ–∏ –∫—Ä–æ–º–µ –ø–æ—Å–ª–µ–¥–Ω–µ–≥–æ
        - **–ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä:** –ü–æ–ª–Ω–æ—Å–≤—è–∑–Ω—ã–π —Å–ª–æ–π —Å 6 –≤—ã—Ö–æ–¥–∞–º–∏
        - **–í—Ö–æ–¥–Ω–æ–π —Ä–∞–∑–º–µ—Ä:** 224√ó224√ó3
        - **–í—ã—Ö–æ–¥–Ω—ã–µ –∫–ª–∞—Å—Å—ã:** 6
        """)

    with col2:
        st.subheader("–ü–∞—Ä–∞–º–µ—Ç—Ä—ã –æ–±—É—á–µ–Ω–∏—è")
        st.info("""
        - **–≠–ø–æ—Ö–∏:** 5
        - **–û–ø—Ç–∏–º–∏–∑–∞—Ç–æ—Ä:** Adam (lr=0.001)
        - **–§—É–Ω–∫—Ü–∏—è –ø–æ—Ç–µ—Ä—å:** CrossEntropyLoss
        - **Batch Size:** 32
        - **–í—Ä–µ–º—è –æ–±—É—á–µ–Ω–∏—è:** ~10 –º–∏–Ω—É—Ç –Ω–∞ GPU
        - **–ú–µ—Ç—Ä–∏–∫–∞:** Accuracy
        """)

    st.markdown("---")

    # –≥—Ä–∞—Ñ–∏–∫–∏ –æ–±—É—á–µ–Ω–∏—è
    st.subheader("–ì—Ä–∞—Ñ–∏–∫–∏ –æ–±—É—á–µ–Ω–∏—è")

    # –¥–∞–Ω–Ω—ã–µ –∏–∑ —á–µ–∫–ø–æ–∏–Ω—Ç–∞
    if checkpoint and 'train_losses' in checkpoint:
        train_losses = checkpoint['train_losses']
        val_losses = checkpoint['val_losses']
        train_accuracies = checkpoint['train_accuracies']
        val_accuracies = checkpoint['val_accuracies']
        class_names = checkpoint.get('class_names', CLASS_NAMES)
    else:
        # –ø—Ä–∏–º–µ—Ä–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ
        train_losses = [0.3730, 0.3720, 0.3713, 0.3727, 0.3674]
        val_losses = [0.3152, 0.2588, 0.2512, 0.2736, 0.2830]
        train_accuracies = [86.47, 86.60, 86.70, 86.55, 86.87]
        val_accuracies = [89.07, 91.27, 91.07, 90.43, 89.37]
        class_names = CLASS_NAMES

    # —Å–æ–∑–¥–∞–µ–º –≥—Ä–∞—Ñ–∏–∫–∏
    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))

    # –≥—Ä–∞—Ñ–∏–∫ Loss
    epochs = range(1, len(train_losses) + 1)
    ax1.plot(epochs, train_losses, 'o-', linewidth=2, markersize=8, label='Train Loss')
    ax1.plot(epochs, val_losses, 's-', linewidth=2, markersize=8, label='Validation Loss')
    ax1.set_title('Loss Curves', fontsize=14, fontweight='bold')
    ax1.set_xlabel('Epoch')
    ax1.set_ylabel('Loss')
    ax1.legend()
    ax1.grid(True, alpha=0.3)

    # –≥—Ä–∞—Ñ–∏–∫ Accuracy
    ax2.plot(epochs, train_accuracies, 'o-', linewidth=2, markersize=8, label='Train Accuracy')
    ax2.plot(epochs, val_accuracies, 's-', linewidth=2, markersize=8, label='Validation Accuracy')
    ax2.set_title('Accuracy Curves', fontsize=14, fontweight='bold')
    ax2.set_xlabel('Epoch')
    ax2.set_ylabel('Accuracy (%)')
    ax2.legend()
    ax2.grid(True, alpha=0.3)

    st.pyplot(fig)

    # –º–µ—Ç—Ä–∏–∫–∏ –æ–±—É—á–µ–Ω–∏—è
    st.subheader("–ú–µ—Ç—Ä–∏–∫–∏ –æ–±—É—á–µ–Ω–∏—è")

    col1, col2, col3, col4 = st.columns(4)

    with col1:
        st.metric("–õ—É—á—à–∞—è —Ç–æ—á–Ω–æ—Å—Ç—å", f"{max(val_accuracies):.2f}%")
    with col2:
        st.metric("–§–∏–Ω–∞–ª—å–Ω–∞—è —Ç–æ—á–Ω–æ—Å—Ç—å", f"{val_accuracies[-1]:.2f}%")
    with col3:
        st.metric("–§–∏–Ω–∞–ª—å–Ω—ã–π Loss", f"{val_losses[-1]:.4f}")
    with col4:
        st.metric("–í—Ä–µ–º—è –æ–±—É—á–µ–Ω–∏—è", "10 –º–∏–Ω—É—Ç")

    st.markdown("---")

    # # F1 Score –∏ Confusion Matrix
    # st.subheader("üéØ –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –º–µ—Ç—Ä–∏–∫–∏")

    # col1, col2 = st.columns(2)

    # with col1:
    #     st.subheader("F1 Score –ø–æ –∫–ª–∞—Å—Å–∞–º")
    #     # –ü—Ä–∏–º–µ—Ä–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è F1 Score (–º–æ–∂–Ω–æ –∑–∞–º–µ–Ω–∏—Ç—å —Ä–µ–∞–ª—å–Ω—ã–º–∏)
    #     f1_scores = {
    #         'buildings': 0.87,
    #         'forest': 0.92,
    #         'glacier': 0.89,
    #         'mountain': 0.85,
    #         'sea': 0.91,
    #         'street': 0.88
    #     }

    #     for class_name, score in f1_scores.items():
    #         st.progress(score, text=f"{class_name}: {score:.3f}")

    # with col2:
    #     st.subheader("Confusion Matrix")
    #     # –ü—Ä–∏–º–µ—Ä–Ω–∞—è confusion matrix
    #     confusion_matrix = np.array([
    #         [420, 15, 8, 12, 5, 10],
    #         [10, 450, 5, 8, 12, 5],
    #         [8, 6, 430, 15, 20, 6],
    #         [15, 10, 12, 400, 8, 15],
    #         [5, 15, 18, 6, 435, 6],
    #         [12, 8, 5, 18, 7, 430]
    #     ])

    #     fig_cm, ax_cm = plt.subplots(figsize=(8, 6))
    #     sns.heatmap(confusion_matrix, annot=True, fmt='d', cmap='Blues',
    #                xticklabels=class_names, yticklabels=class_names)
    #     ax_cm.set_title('Confusion Matrix', fontweight='bold')
    #     ax_cm.set_xlabel('Predicted')
    #     ax_cm.set_ylabel('Actual')
    #     st.pyplot(fig_cm)

    # st.markdown("---")

    # # –ü—Ä–∏–º–µ—Ä –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –∏–∑ –¥–∞—Ç–∞—Å–µ—Ç–∞
    # st.subheader("–ü—Ä–∏–º–µ—Ä –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –∏–∑ –¥–∞—Ç–∞—Å–µ—Ç–∞")

    # # –°–æ–∑–¥–∞–µ–º –ø—Ä–∏–º–µ—Ä –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
    # fig_example, ax_example = plt.subplots(figsize=(8, 6))
    # demo_image = np.random.rand(150, 150, 3)
    # ax_example.imshow(demo_image)
    # ax_example.set_title('–ü—Ä–∏–º–µ—Ä: mountain', fontweight='bold')
    # ax_example.axis('off')
    # st.pyplot(fig_example)

    # st.info("–≠—Ç–æ –ø—Ä–∏–º–µ—Ä –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –∏–∑ —Ç–µ—Å—Ç–æ–≤–æ–≥–æ –Ω–∞–±–æ—Ä–∞ –¥–∞–Ω–Ω—ã—Ö")

# –°—Ç—Ä–∞–Ω–∏—Ü–∞ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏
def show_classification_page():
    st.title("–ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π")
    st.markdown("---")

    # –ó–∞–≥—Ä—É–∂–∞–µ–º –º–æ–¥–µ–ª—å
    model, checkpoint = load_model()

    if model is None:
        st.error("–ú–æ–¥–µ–ª—å –Ω–µ –∑–∞–≥—Ä—É–∂–µ–Ω–∞")
        return

    transforms = get_transforms()
    class_names = checkpoint.get('class_names', CLASS_NAMES) if checkpoint else CLASS_NAMES

    # –°–ø–æ—Å–æ–±—ã –∑–∞–≥—Ä—É–∑–∫–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
    option = st.radio("–í—ã–±–µ—Ä–∏—Ç–µ —Å–ø–æ—Å–æ–± –∑–∞–≥—Ä—É–∑–∫–∏:",
                     ["–ó–∞–≥—Ä—É–∑–∏—Ç—å —Ñ–∞–π–ª", "–í–≤–µ—Å—Ç–∏ URL"])

    image = None

    if option == "–ó–∞–≥—Ä—É–∑–∏—Ç—å —Ñ–∞–π–ª":
        uploaded_file = st.file_uploader("–í—ã–±–µ—Ä–∏—Ç–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ",
                                       type=['jpg', 'jpeg', 'png'])
        if uploaded_file is not None:
            image = Image.open(uploaded_file)

    else:  # URL
        url = st.text_input("–í–≤–µ–¥–∏—Ç–µ URL –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è:",
                           placeholder="https://example.com/image.jpg")
        if url:
            with st.spinner("–ó–∞–≥—Ä—É–∂–∞–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ..."):
                image = load_image_from_url(url)

    # –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ
    if image is not None:
        col1, col2 = st.columns(2)

        with col1:
            st.subheader("–ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ")
            st.image(image, use_column_width=True)

            # –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ
            with st.spinner("–ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ..."):
                predicted_class, confidence, probabilities, inference_time = predict_image(
                    model, image, transforms
                )

        with col2:
            st.subheader("–†–µ–∑—É–ª—å—Ç–∞—Ç –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏")

            # –æ—Å–Ω–æ–≤–Ω–æ–µ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ
            st.success(f"**–ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–Ω—ã–π –∫–ª–∞—Å—Å:** {class_names[predicted_class]}")
            st.info(f"**–£–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å:** {confidence:.2%}")

            # –≤—Ä–µ–º—è –æ—Ç–≤–µ—Ç–∞ –º–æ–¥–µ–ª–∏
            st.metric("–í—Ä–µ–º—è –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è", f"{inference_time:.3f} —Å–µ–∫—É–Ω–¥")

            # –≤—Å–µ –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–∏
            st.subheader("–í–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–∏ –ø–æ –∫–ª–∞—Å—Å–∞–º:")
            for i, (class_name, prob) in enumerate(zip(class_names, probabilities)):
                progress = int(prob * 100)
                if i == predicted_class:
                    st.markdown(f"**{class_name}:** {prob:.4f} ({progress}%)")
                    st.progress(progress / 100)
                else:
                    st.write(f"‚Ä¢ {class_name}: {prob:.4f} ({progress}%)")

            # –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–µ–π
            st.subheader("–í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–µ–π")
            prob_df = pd.DataFrame({
                'Class': class_names,
                'Probability': probabilities.numpy()
            })
            prob_df = prob_df.sort_values('Probability', ascending=False)

            fig_bar = px.bar(prob_df, x='Class', y='Probability',
                           color='Probability', color_continuous_scale='viridis')
            fig_bar.update_layout(title='–í–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–∏ –ø–æ –∫–ª–∞—Å—Å–∞–º', showlegend=False)
            st.plotly_chart(fig_bar, use_container_width=True)

# –æ—Å–Ω–æ–≤–Ω–æ–µ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–µ
def main():
    st.sidebar.title("–ù–∞–≤–∏–≥–∞—Ü–∏—è")
    page = st.sidebar.radio("–í—ã–±–µ—Ä–∏—Ç–µ —Å—Ç—Ä–∞–Ω–∏—Ü—É:",
                           ["–ì–ª–∞–≤–Ω–∞—è", "–ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π"])

    st.sidebar.markdown("---")
    st.sidebar.info("""
    **–û –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–∏:**
    - –ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π Intel
    - 6 –∫–ª–∞—Å—Å–æ–≤: buildings, forest, glacier, mountain, sea, street
    - –ú–æ–¥–µ–ª—å: ResNet50 —Å Transfer Learning
    - –¢–æ—á–Ω–æ—Å—Ç—å: ~90%
    - –ü—É—Ç—å –∫ –º–æ–¥–µ–ª–∏: {}
    """.format(MODEL_PATH))

    if page == "–ì–ª–∞–≤–Ω–∞—è":
        show_main_page()
    else:
        show_classification_page()

if __name__ == "__main__":
    main()